\section{Evaluation}\label{sec:eval}

In this section we answer the following questions:

\begin{enumerate}
  \item What shape does the cipher configuration tradeoff space take under our
  workloads? (\cref{subsec:eval-baseline})
  \item Can \sys achieve dynamic security/energy tradeoffs by reaching
  configuration points not accessible with prior work?
  (\cref{subsec:eval-dynamic})
  \item What is the performance and storage overhead of each switching model?
  (\cref{subsec:eval-overhead})
\end{enumerate}

\mysub{Experimental Setup.} We implement \sys and our experiments on a
Hardkernel Odroid XU3 ARM big.LITTLE system with Samsung Exynos 5422 A15/A7
heterogeneous multi-processing quad core CPUs at maximum clock speed, 2 gigabyte
LPDDR3 RAM at 933 MHz, and an eMMC5.0 HS400 backing store running Ubuntu Trusty
14.04.6 LTS, kernel version 3.10.106. Energy monitoring was provided by the
Odroid's integrated INA-231 power sensors polled every $\approx{260}$
milliseconds (not including noise/overhead).

We evaluate \sys using a Linux RAM disk (tmpfs). The maximum theoretical memory
bandwidth for this Odroid model is 14.9GB/s\@. Our observed maximum memory
bandwidth is 4.5GB/s. Using a RAM disk focuses the evaluation on the performance
differences due to different ciphers. All experiments are performed with basic
Linux I/O commands, bypassing system caching.

\mysub{Methodology.} In each experiment below, we evaluate \sys on two high
level workloads: sequential and random I/O. In both workloads, a number of bytes
are written and then read (either 4KB, 512KB, 5MB, 40MB) 10 times. Each workload
is repeated three times for a total of 240 tests per crypt (720 runs per {\em
ratio}, see below); 30 results per byte size, 120 results per workload. Results
are accumulated and the median is taken.

When evaluating switching models, a finer breakdown in workloads is made using a
pre-selected pair of crypts we call the {\em primary} and {\em secondary}. \sys
is initialized using the primary crypt. Once we trigger a switch, the secondary
crypt is used. The switch is triggered according to a certain {\em ratio} of I/O
operations. For example: given 10 40MB ``write-read'' (write and then read back)
operations, we may write-read 40MB 3 times using the primary crypt, initiate a
switch, and then write-read 40MB 7 times. This would be a 3:7 ratio. It follows
that there are three ratios we use to evaluate \sys's performance in this
regard: 7:3, 5:5, and 3:7.


% =======================================================
\subsection{Switching Models Under Load}\label{subsec:eval-baseline}

\input{graphics/fig-eval-baseline}

\Cref{fig:eval-baseline} shows the normalized relative rounds and ciphertext
randomization (normed R+R vector) versus median normalized latency tradeoff
between different stream cipher configurations for our sequential and random I/O
workloads. Trends for median hold when looking at tail latencies as well. Each
line represents one workload: 4KB, 512KB, 5MB, and 40MB respectively (see
legend). Each symbol represents one of our ciphers: ChaCha8, ChaCha20, Freestyle
Fast, Freestyle Balanced, and Freestyle Strong. Of the ciphers we tested, those
with higher rounds and higher ciphertext randomization scores resulted in higher
overall latency and increased energy use for I/O operations. The relationship
between these concerns is not always linear, however, which exposes a rich
tradeoff space.

Besides the 4KB workload, the shape of each workload follows a similar trend,
hence we will focus on 40MB and 4KB workloads going forward. Due to the overhead
of metadata management and the fast completion time of the 4KB workloads
(\ie{little time for amortization of overhead}), ChaCha8 and ChaCha20 take
longer to complete than Freestyle Fast. This advantage is not enough to make
Freestyle Balanced or Secure workloads complete faster than the ChaCha variants,
however.

Though ChaCha8 is faster than ChaCha20, there is some variability in our timing
setup when capturing extremely fast events occurring close together in time.
This is why ChaCha8 sometimes appears with higher latency than ChaCha20 for
normalized 4KB workloads. ChaCha8 is not slower than ChaCha20.


% =======================================================
\subsection{The Heterogeneous FDE Solution}\label{subsec:eval-dynamic}

\input{graphics/fig-eval-forward}

\Cref{fig:eval-forward} shows the normalized relative rounds and ciphertext
randomization (normed R+R vector) versus median normalized latency tradeoff
between different stream ciphers for our sequential and random I/O workloads
with switching using the Forward model. After a certain number of write-read I/O
operations, a switch is initiated and \sys begins using the secondary cipher to
encrypt and decrypt data. For each pair of ciphers, this is repeated three
times: once at every ratio point {\em between} our static configuration points
(\ie{7:3, 5:5, and 3:7 described above}).

The point of this experiment is to determine if \sys can effectively transition
the drive between ciphers without devastating performance. For the 40MB, 5MB,
and 512KB workloads (40MB is shown), we see that \sys can achieve dynamic
security/energy tradeoffs reaching points not accessible with prior work, all
with minimal overhead.

Again, due to the overhead of metadata management for non-Freestyle ciphers (see
\cref{sec:impl}) and the fast completion time of the 4KB workloads preventing
\sys from taking advantage of amortization, ChaCha8 and ChaCha20 take longer to
complete than Freestyle Fast for 4KB reads. We also see very high latency for
ratios between Freestyle Fast and Freestyle Strong cipher configurations. This
is because Freestyle is not length-preserving, so extra write operations must be
performed, and the algorithm itself is generally much slower than the ChaCha
variants (see \cref{fig:eval-baseline}). Doubly invoking Freestyle in a ratio
configuration means these penalties are paid more often.

\input{graphics/fig-eval-ms}

\Cref{fig:eval-ms} shows the performance of the Mirrored and Selective models
with the same configuration of ratios as \cref{fig:eval-forward}.

For the 40MB, 5MB, and 512KB workloads (40MB is shown), we see that Mirrored and
Selective {\em read} workloads and the Selective {\em write} workload achieve
parity with the Forward model experiments. This makes sense, as most of the
overhead for Selective and Mirrored reads is determining which part of the drive
to commit data to. The same applies to Selective writes. For the 4KB Mirrored
and Selective {\em read} workloads and the Selective {\em write} workload, we
see behavior similar to that in \cref{fig:eval-forward}, as expected.

Mirrored writes across all workloads are very slow. This is to be expected,
since the data is being mirrored across all areas of the drive. In our
experiments, the drive can be considered partitioned in half. This overhead is
most egregious for the 4KB Mirrored write workload. This makes Selective
preferable to Mirrored. However, it is a tradeoff; Selective cannot quickly
converge the drive to a single cipher configuration or survive the loss of an
entire region.


% =======================================================
\subsection{Switching Overhead}\label{subsec:eval-overhead}

We calculate that Forward switching has average overhead at 0.08x/0.10x for
40MB, 5MB and 512KB read/write workloads compared to baseline I/O, demonstrating
\sys's amortization of switching costs. Average overhead is\\0.38x/0.44x for 4KB
read/write workloads when \sys is unable to amortize cost. There is no spatial
overhead with the Forward switching model.

Similarly, we calculate that Selective switching has average overhead at 0x/0.3x
for 40MB, 5MB and 512KB read/write workloads compared to baseline I/O. Average
overhead is 0.22x/0.71x for 4KB read/write workloads. Spatial overhead in our
experiment was half of all writable space on the drive.

Finally, we calculate that Mirrored switching has average overhead at
0.25x/0.61x for 40MB, 5MB and 512KB read/write workloads compared to baseline
I/O, with high write latency due to mirroring. Average overhead is 0.55x/0.77x
for 4KB read/write workloads. Spatial overhead in our experiment was half of all
writable space on the drive.

These overhead numbers are the penalty paid for the additional flexibility of
being able to reach configurations points that are unachievable without \sys.
\sys's design keeps these overheads acceptably low in practice, achieving the
desired goal of flexibly navigating latency/security tradeoffs for FDE.
